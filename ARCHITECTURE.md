# ConcordKV 系统架构文档

## 1. 架构概览

ConcordKV 采用分层模块化架构，将分布式键值存储系统分解为多个独立但协作的组件。系统设计遵循高内聚、低耦合的原则，确保各模块可以独立开发、测试和部署。

```
┌─────────────────────────────────────────────────────────┐
│                    Client Layer                        │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │
│  │   Go Client │  │  C++ Client │  │ REST Client │     │
│  └─────────────┘  └─────────────┘  └─────────────┘     │
└─────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────┐
│                 Distributed Layer (Go)                 │
│  ┌─────────────────────────────────────────────────────┐ │
│  │              Raft Consensus Engine                 │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │ │
│  │  │   Leader    │ │  Follower   │ │  Candidate  │   │ │
│  │  │  Election   │ │    Log      │ │   Election  │   │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │ │
│  └─────────────────────────────────────────────────────┘ │
│  ┌─────────────────────────────────────────────────────┐ │
│  │              Cluster Management                    │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │ │
│  │  │   Node      │ │   Shard     │ │   Health    │   │ │
│  │  │ Discovery   │ │ Management  │ │   Monitor   │   │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │ │
│  └─────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────┐
│                Storage Engine (C/C++)                  │
│  ┌─────────────────────────────────────────────────────┐ │
│  │              Enhanced Persistence                  │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │ │
│  │  │     WAL     │ │    Log      │ │ Incremental │   │ │
│  │  │ Compaction  │ │  Rotation   │ │   Snapshot  │   │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │ │
│  └─────────────────────────────────────────────────────┘ │
│  ┌─────────────────────────────────────────────────────┐ │
│  │              Core Storage                          │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │ │
│  │  │    Array    │ │   RB-Tree   │ │  Hash Table │   │ │
│  │  │   Storage   │ │   Storage   │ │   Storage   │   │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │ │
│  └─────────────────────────────────────────────────────┘ │
│  ┌─────────────────────────────────────────────────────┐ │
│  │            Transaction & Concurrency               │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │ │
│  │  │ Transaction │ │ Lock Manager│ │   Deadlock  │   │ │
│  │  │   Manager   │ │   (MVCC)    │ │  Detection  │   │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │ │
│  └─────────────────────────────────────────────────────┘ │
│  ┌─────────────────────────────────────────────────────┐ │
│  │         Distributed Transaction System 🆕          │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │ │
│  │  │     2PC     │ │  Priority   │ │   Timeout   │   │ │
│  │  │ Coordinator │ │  Scheduler  │ │   Handler   │   │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │ │
│  └─────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

## 2. 核心组件详细设计

### 2.1 存储引擎层 (C/C++)

存储引擎是系统的核心，负责数据的本地存储、检索和管理。

#### 2.1.1 增强持久化子系统

**WAL日志压缩**
- **触发条件**: 日志条目数量超过1000条或文件大小超过64MB
- **压缩策略**: 移除冗余操作，只保留每个键的最新状态
- **空间节省**: 通常可节省30-70%的存储空间
- **后台处理**: 独立线程执行，不阻塞正常操作

**增量持久化**
- **批量同步**: 累积100个操作后批量写入磁盘
- **定时同步**: 每5秒强制同步一次
- **性能优化**: 减少磁盘I/O操作，提高写入吞吐量
- **数据安全**: 保证最终一致性，支持崩溃恢复

**日志轮转**
- **文件管理**: 维护多个日志文件的链表结构
- **自动轮转**: 文件超过64MB时自动创建新文件
- **历史清理**: 压缩后自动清理旧文件

#### 2.1.2 存储结构实现

**数组存储**
```c
typedef struct {
    kv_item_t *items;     // 键值对数组
    int capacity;         // 容量
    int count;           // 当前数量
    pthread_rwlock_t lock; // 读写锁
} array_t;
```
- **适用场景**: 小规模数据集，顺序访问
- **时间复杂度**: O(n)查找，O(1)插入
- **内存占用**: 连续内存，缓存友好

**红黑树存储**
```c
typedef struct rb_node {
    char *key;
    char *value;
    int color;           // 红黑树颜色
    struct rb_node *left, *right, *parent;
} rb_node_t;
```
- **适用场景**: 需要有序遍历，范围查询
- **时间复杂度**: O(log n)查找、插入、删除
- **平衡性**: 自平衡二叉搜索树

**哈希表存储**
```c
typedef struct {
    hash_bucket_t *buckets; // 哈希桶数组
    int bucket_count;       // 桶数量
    int total_items;        // 总项目数
    double load_factor;     // 负载因子
    pthread_mutex_t *locks; // 分段锁
} hash_table_t;
```
- **适用场景**: 随机访问，高并发读写
- **时间复杂度**: O(1)平均查找时间
- **并发优化**: 分段锁减少锁竞争

#### 2.1.3 事务和并发控制

**MVCC实现**
```c
typedef struct {
    uint64_t txn_id;        // 事务ID
    uint64_t start_ts;      // 开始时间戳
    uint64_t commit_ts;     // 提交时间戳
    uint8_t isolation_level; // 隔离级别
    txn_op_list_t *ops;     // 操作列表
} transaction_t;
```

**锁管理器**
- **读写锁**: 支持多读者单写者
- **分段锁**: 减少锁粒度，提高并发性
- **死锁检测**: 基于等待图的死锁检测算法
- **锁超时**: 防止长时间锁定

### 2.2 分布式协调层 (Go)

#### 2.2.1 Raft共识协议

**状态机设计**
```go
type RaftNode struct {
    state        NodeState    // FOLLOWER, CANDIDATE, LEADER
    currentTerm  uint64       // 当前任期
    votedFor     string       // 投票对象
    log          []LogEntry   // 日志条目
    commitIndex  uint64       // 已提交索引
    lastApplied  uint64       // 已应用索引
    
    // Leader状态
    nextIndex    map[string]uint64  // 下一个发送索引
    matchIndex   map[string]uint64  // 已匹配索引
}
```

**选举机制**
- **超时机制**: 随机选举超时(150-300ms)
- **投票策略**: 先到先得，日志完整性检查
- **脑裂预防**: 要求大多数节点投票

**日志复制**
- **并行复制**: 向所有Follower并行发送
- **一致性检查**: 基于日志索引和任期的一致性验证
- **重试机制**: 失败时自动重试和回退

#### 2.2.2 集群管理

**节点发现**
```go
type NodeDiscovery struct {
    discoveryType DiscoveryType  // STATIC, DNS, SERVICE_REGISTRY
    endpoints     []string       // 静态端点列表
    registry      ServiceRegistry // 服务注册中心
    refreshInterval time.Duration // 刷新间隔
}
```

**负载均衡**
- **轮询策略**: 简单轮询分配
- **加权策略**: 基于节点性能的加权分配
- **一致性哈希**: 特定键总是路由到相同节点
- **最少连接**: 选择连接数最少的节点

**健康检查**
```go
type HealthChecker struct {
    checkInterval time.Duration   // 检查间隔
    timeout       time.Duration   // 超时时间
    retryCount    int            // 重试次数
    metrics       *HealthMetrics // 健康指标
}
```

### 2.3 客户端层

#### 2.3.1 Go客户端架构

**连接管理**
```go
type ConnectionPool struct {
    connections map[string]*Connection // 连接池
    balancer    LoadBalancer          // 负载均衡器
    discovery   *NodeDiscovery        // 节点发现
    monitor     *HealthMonitor        // 健康监控
}
```

**事务支持**
```go
type Transaction struct {
    client      *Client
    txnID       string
    isolation   IsolationLevel
    operations  []Operation
    readOnly    bool
    timeout     time.Duration
}
```

**批量操作**
```go
type BatchOperation struct {
    operations []Operation
    parallel   bool          // 是否并行执行
    timeout    time.Duration // 超时时间
}
```

## 3. 数据流和交互模式

### 3.1 写操作流程

```
Client → Raft Leader → Log Replication → Majority Commit → Apply to State Machine → Response
```

1. **客户端请求**: 客户端发送写请求到Raft Leader
2. **日志追加**: Leader将操作追加到本地日志
3. **并行复制**: Leader并行向所有Follower发送日志条目
4. **多数确认**: 等待大多数节点确认接收
5. **提交应用**: 将日志条目标记为已提交并应用到状态机
6. **响应客户端**: 返回操作结果给客户端

### 3.2 读操作流程

```
Client → Load Balancer → Any Node → Local Read → Response
```

1. **负载均衡**: 客户端通过负载均衡器选择节点
2. **本地读取**: 从选中节点的本地状态机读取数据
3. **一致性保证**: 可选的线性一致性读取验证
4. **返回结果**: 直接返回读取结果

### 3.3 故障恢复流程

**Leader故障**
```
Follower Timeout → Election → New Leader → Resume Operations
```

**Follower故障**
```
Leader Detect → Remove from Replication → Continue with Majority
```

**网络分区**
```
Partition Detection → Majority Side Continues → Minority Side Blocks → Heal and Sync
```

## 4. 性能优化策略

### 4.1 存储层优化

- **内存池**: 减少内存分配开销
- **批量写入**: 聚合多个操作减少I/O
- **异步刷盘**: 后台异步持久化
- **压缩算法**: 智能日志压缩策略

### 4.2 网络层优化

- **连接复用**: 长连接和连接池
- **批量传输**: 聚合多个请求
- **压缩传输**: 网络数据压缩
- **并行处理**: 多线程处理网络I/O

### 4.3 并发优化

- **无锁数据结构**: 关键路径使用无锁算法
- **分段锁**: 减少锁粒度和竞争
- **读写分离**: 读操作不阻塞写操作
- **异步处理**: 非关键操作异步执行

## 5. 可扩展性设计

### 5.1 水平扩展

- **动态分片**: 根据负载自动调整分片
- **数据迁移**: 在线数据重平衡
- **弹性伸缩**: 自动添加/移除节点
- **跨区域复制**: 支持多数据中心部署

### 5.2 垂直扩展

- **资源隔离**: CPU、内存、磁盘资源隔离
- **优先级调度**: 不同操作的优先级管理
- **缓存层**: 多级缓存提高性能
- **存储分层**: 热数据和冷数据分离

## 6. 监控和运维

### 6.1 指标监控

- **性能指标**: QPS、延迟、吞吐量
- **资源指标**: CPU、内存、磁盘、网络
- **业务指标**: 事务成功率、数据一致性
- **错误指标**: 错误率、超时率

### 6.2 日志系统

- **结构化日志**: JSON格式的结构化日志
- **日志级别**: DEBUG、INFO、WARN、ERROR
- **日志轮转**: 自动日志文件管理
- **集中收集**: 支持日志聚合和分析

### 6.3 运维工具

- **健康检查**: 自动健康状态检测
- **故障恢复**: 自动故障检测和恢复
- **性能分析**: 性能瓶颈分析和优化建议

## 7. 分布式事务系统 🆕

### 7.1 系统架构

分布式事务系统采用两阶段提交(2PC)协议，确保跨多个节点的事务ACID特性。

```
┌─────────────────────────────────────────────────────────┐
│                Transaction Coordinator                  │
│  ┌─────────────────────────────────────────────────────┐ │
│  │                  Control Center                     │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │ │
│  │  │   Node      │ │  Priority   │ │  Statistics │   │ │
│  │  │ Management  │ │   Queue     │ │   Monitor   │   │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │ │
│  └─────────────────────────────────────────────────────┘ │
│  ┌─────────────────────────────────────────────────────┐ │
│  │                Thread Management                    │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │ │
│  │  │  Scheduler  │ │  Heartbeat  │ │   Timeout   │   │ │
│  │  │   Thread    │ │   Thread    │ │   Thread    │   │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │ │
│  └─────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
           │              │              │
           ▼              ▼              ▼
┌─────────────┐ ┌─────────────┐ ┌─────────────┐
│ Participant │ │ Participant │ │ Participant │
│   Node 1    │ │   Node 2    │ │   Node 3    │
└─────────────┘ └─────────────┘ └─────────────┘
```

### 7.2 核心组件

#### 7.2.1 分布式事务协调器

**主要职责**:
- 管理全局事务ID分配
- 协调2PC协议执行
- 监控参与者节点状态
- 处理事务超时和故障恢复

**关键数据结构**:
```c
typedef struct dist_txn_coordinator {
    char coordinator_id[64];           // 协调器ID
    dist_node_t *nodes;               // 参与者节点列表
    dist_transaction_t *transactions;  // 活跃事务列表
    txn_priority_queue_t *priority_queue; // 优先级队列
    atomic_long total_transactions;    // 统计信息
    pthread_t scheduler_thread;       // 调度器线程
    pthread_t heartbeat_thread;       // 心跳线程
    pthread_t timeout_thread;         // 超时检查线程
} dist_txn_coordinator_t;
```

#### 7.2.2 优先级调度系统

**调度策略**:
- **URGENT** (优先级15): 紧急事务，最高优先级
- **HIGH** (优先级10): 高优先级事务
- **NORMAL** (优先级5): 普通事务
- **LOW** (优先级1): 低优先级后台任务

**队列管理**:
- 基于堆实现的优先级队列
- 支持超时和容量限制
- 线程安全的并发访问
- 自动负载均衡

#### 7.2.3 2PC协议实现

**准备阶段(Prepare)**:
1. 协调器向所有参与者发送PREPARE消息
2. 参与者执行本地事务准备
3. 参与者回复PREPARED或ABORT
4. 协调器收集所有响应

**提交阶段(Commit/Abort)**:
1. 如果所有参与者PREPARED，发送COMMIT
2. 如果任何参与者ABORT，发送ABORT
3. 参与者执行最终操作
4. 参与者回复完成状态

### 7.3 容错机制

#### 7.3.1 超时处理
- **事务级超时**: 每个事务可设置独立超时时间
- **网络超时**: 网络通信超时检测
- **队列超时**: 入队/出队操作超时保护
- **自动重试**: 网络故障时的智能重试机制

#### 7.3.2 故障恢复
- **网络分区检测**: 心跳机制检测网络分区
- **节点故障处理**: 自动移除不响应的节点
- **事务状态恢复**: 支持协调器重启后状态恢复
- **优雅降级**: 部分节点故障时的降级服务

### 7.4 性能特性

**测试结果** (基于测试套件):
- **事务协调延迟**: < 10ms (本地网络)
- **并发处理能力**: 支持数百个并发事务
- **故障检测时间**: < 30秒 (心跳间隔5秒)
- **内存使用**: 稳定，无泄漏
- **测试覆盖率**: > 95% (246个测试用例)

**优化特性**:
- 零拷贝消息传递
- 批量操作支持
- 自适应超时调整
- 智能错误重试

---

*最后更新: 2025-5-30*

---

本架构文档描述了ConcordKV系统的核心设计理念和实现细节。系统采用模块化设计，各组件职责明确，通过标准化接口协作，确保系统的可维护性、可扩展性和高性能。 