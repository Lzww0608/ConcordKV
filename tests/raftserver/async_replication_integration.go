package main

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"
)

// ===== åŸºç¡€ç±»å‹å®šä¹‰ =====

// NodeID èŠ‚ç‚¹IDç±»å‹
type NodeID string

// DataCenterID æ•°æ®ä¸­å¿ƒIDç±»å‹
type DataCenterID string

// LogIndex æ—¥å¿—ç´¢å¼•ç±»å‹
type LogIndex uint64

// Term Raftä»»æœŸç±»å‹
type Term uint64

// LogEntry Raftæ—¥å¿—æ¡ç›®
type LogEntry struct {
	Index LogIndex
	Term  Term
	Data  []byte
}

// Snapshot Raftå¿«ç…§
type Snapshot struct {
	Index LogIndex
	Term  Term
	Data  []byte
}

// DataCenter æ•°æ®ä¸­å¿ƒé…ç½®
type DataCenter struct {
	ID     DataCenterID
	Region string
}

// ServerConfig æœåŠ¡å™¨é…ç½®
type ServerConfig struct {
	ID         NodeID
	DataCenter DataCenterID
	Address    string
}

// MultiDCConfig å¤šæ•°æ®ä¸­å¿ƒé…ç½®
type MultiDCConfig struct {
	Enabled         bool
	LocalDataCenter DataCenter
}

// Config Rafté…ç½®
type Config struct {
	NodeID  NodeID
	MultiDC *MultiDCConfig
	Servers []ServerConfig
}

// Transport ä¼ è¾“å±‚æ¥å£
type Transport interface {
	Send(nodeID NodeID, req interface{}) error
	Receive() (interface{}, error)
}

// Storage å­˜å‚¨å±‚æ¥å£
type Storage interface {
	SaveLogEntries(entries []LogEntry) error
	GetLogEntries(startIndex, endIndex LogIndex) ([]LogEntry, error)
	SaveSnapshot(snapshot Snapshot) error
	GetSnapshot() (Snapshot, error)
}

// RequestType è¯·æ±‚ç±»å‹
type RequestType int

const (
	RequestTypeRead RequestType = iota
	RequestTypeWrite
)

// ReadConsistencyLevel è¯»ä¸€è‡´æ€§çº§åˆ«
type ReadConsistencyLevel int

const (
	ReadConsistencyEventual     ReadConsistencyLevel = iota // æœ€ç»ˆä¸€è‡´æ€§
	ReadConsistencyBounded                                  // æœ‰ç•Œä¸€è‡´æ€§
	ReadConsistencyStrong                                   // å¼ºä¸€è‡´æ€§
	ReadConsistencyLinearizable                             // çº¿æ€§ä¸€è‡´æ€§
)

// ===== å¼‚æ­¥å¤åˆ¶ç›¸å…³ç±»å‹ =====

// AsyncReplicationConfig å¼‚æ­¥å¤åˆ¶é…ç½®
type AsyncReplicationConfig struct {
	BatchSize          int           // æ‰¹æ¬¡å¤§å°
	FlushInterval      time.Duration // åˆ·æ–°é—´éš”
	RetryDelay         time.Duration // é‡è¯•å»¶è¿Ÿ
	MaxRetries         int           // æœ€å¤§é‡è¯•æ¬¡æ•°
	CompressionEnabled bool          // æ˜¯å¦å¯ç”¨å‹ç¼©
	MonitoringEnabled  bool          // æ˜¯å¦å¯ç”¨ç›‘æ§
}

// AsyncReplicationTarget å¼‚æ­¥å¤åˆ¶ç›®æ ‡
type AsyncReplicationTarget struct {
	DataCenterID        DataCenterID
	NodeList            []NodeID
	LastReplicatedIndex LogIndex
	LastReplicatedTerm  Term
	LastReplicationTime time.Time
	PendingBatches      int
	ReplicationLatency  time.Duration
	IsHealthy           bool
	HealthCheckTime     time.Time
	NetworkLatency      time.Duration
	ThroughputMBps      float64
}

// AsyncReplicationMetrics å¼‚æ­¥å¤åˆ¶æŒ‡æ ‡
type AsyncReplicationMetrics struct {
	TotalBatchesSent       uint64
	TotalEntriesReplicated uint64
	TotalBytesTransferred  uint64
	AverageLatency         time.Duration
	MaxLatency             time.Duration
	MinLatency             time.Duration
	SuccessRate            float64
	ErrorCount             uint64
	RetryCount             uint64
	LastErrorTime          time.Time
	DataCenterMetrics      map[DataCenterID]*DataCenterMetrics
}

// DataCenterMetrics æ•°æ®ä¸­å¿ƒæŒ‡æ ‡
type DataCenterMetrics struct {
	BatchesSent       uint64
	EntriesReplicated uint64
	BytesTransferred  uint64
	AverageLatency    time.Duration
	SuccessRate       float64
	ErrorCount        uint64
}

// AsyncReplicator å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
type AsyncReplicator struct {
	nodeID     NodeID
	config     *AsyncReplicationConfig
	raftConfig *Config
	transport  Transport
	storage    Storage
	targets    map[DataCenterID]*AsyncReplicationTarget
	metrics    *AsyncReplicationMetrics
	ctx        context.Context
	cancel     context.CancelFunc
	isRunning  bool
	mu         sync.RWMutex
}

// NewAsyncReplicator åˆ›å»ºæ–°çš„å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
func NewAsyncReplicator(nodeID NodeID, raftConfig *Config, transport Transport, storage Storage) *AsyncReplicator {
	config := &AsyncReplicationConfig{
		BatchSize:          100,
		FlushInterval:      1 * time.Second,
		RetryDelay:         500 * time.Millisecond,
		MaxRetries:         3,
		CompressionEnabled: true,
		MonitoringEnabled:  true,
	}

	ctx, cancel := context.WithCancel(context.Background())

	return &AsyncReplicator{
		nodeID:     nodeID,
		config:     config,
		raftConfig: raftConfig,
		transport:  transport,
		storage:    storage,
		targets:    make(map[DataCenterID]*AsyncReplicationTarget),
		metrics: &AsyncReplicationMetrics{
			DataCenterMetrics: make(map[DataCenterID]*DataCenterMetrics),
		},
		ctx:       ctx,
		cancel:    cancel,
		isRunning: false,
	}
}

// Start å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
func (ar *AsyncReplicator) Start() error {
	ar.mu.Lock()
	defer ar.mu.Unlock()

	if ar.isRunning {
		return nil
	}

	// åˆå§‹åŒ–å¤åˆ¶ç›®æ ‡
	for _, server := range ar.raftConfig.Servers {
		if server.DataCenter != ar.raftConfig.MultiDC.LocalDataCenter.ID {
			target := &AsyncReplicationTarget{
				DataCenterID:    server.DataCenter,
				NodeList:        []NodeID{server.ID},
				IsHealthy:       true,
				HealthCheckTime: time.Now(),
			}
			ar.targets[server.DataCenter] = target
			ar.metrics.DataCenterMetrics[server.DataCenter] = &DataCenterMetrics{}
		}
	}

	ar.isRunning = true
	return nil
}

// Stop åœæ­¢å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
func (ar *AsyncReplicator) Stop() error {
	ar.mu.Lock()
	defer ar.mu.Unlock()

	if !ar.isRunning {
		return nil
	}

	ar.cancel()
	ar.isRunning = false
	return nil
}

// ReplicateAsync æ‰§è¡Œå¼‚æ­¥å¤åˆ¶
func (ar *AsyncReplicator) ReplicateAsync(entries []LogEntry) error {
	ar.mu.RLock()
	defer ar.mu.RUnlock()

	if !ar.isRunning {
		return fmt.Errorf("å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨æœªè¿è¡Œ")
	}

	// æ›´æ–°æŒ‡æ ‡
	ar.metrics.TotalEntriesReplicated += uint64(len(entries))
	ar.metrics.TotalBatchesSent++

	// æ¨¡æ‹Ÿå¼‚æ­¥å¤åˆ¶å¤„ç†
	go func() {
		for dcID := range ar.targets {
			log.Printf("å¼‚æ­¥å¤åˆ¶åˆ°DC %s: %dæ¡æ—¥å¿—æ¡ç›®", dcID, len(entries))
		}
	}()

	return nil
}

// GetReplicationStatus è·å–å¤åˆ¶çŠ¶æ€
func (ar *AsyncReplicator) GetReplicationStatus() map[DataCenterID]*AsyncReplicationTarget {
	ar.mu.RLock()
	defer ar.mu.RUnlock()

	status := make(map[DataCenterID]*AsyncReplicationTarget)
	for dcID, target := range ar.targets {
		// å¤åˆ¶ä¸€ä»½çŠ¶æ€é¿å…å¹¶å‘é—®é¢˜
		statusCopy := *target
		status[dcID] = &statusCopy
	}
	return status
}

// GetMetrics è·å–å¤åˆ¶æŒ‡æ ‡
func (ar *AsyncReplicator) GetMetrics() *AsyncReplicationMetrics {
	ar.mu.RLock()
	defer ar.mu.RUnlock()

	// è¿”å›æŒ‡æ ‡çš„å‰¯æœ¬
	metricsCopy := *ar.metrics
	return &metricsCopy
}

// ===== è¯»å†™åˆ†ç¦»è·¯ç”±ç›¸å…³ç±»å‹ =====

// RoutingDecision è·¯ç”±å†³ç­–
type RoutingDecision struct {
	RequestType       RequestType
	TargetNode        NodeID
	TargetDC          DataCenterID
	Latency           time.Duration
	ConsistencyLevel  ReadConsistencyLevel
	LoadBalanceReason string
}

// ReadWriteRouterConfig è¯»å†™åˆ†ç¦»è·¯ç”±å™¨é…ç½®
type ReadWriteRouterConfig struct {
	LoadBalanceAlgorithm string        // è´Ÿè½½å‡è¡¡ç®—æ³•
	HealthCheckInterval  time.Duration // å¥åº·æ£€æŸ¥é—´éš”
	MaxLatencyThreshold  time.Duration // æœ€å¤§å»¶è¿Ÿé˜ˆå€¼
	EnableMetrics        bool          // æ˜¯å¦å¯ç”¨æŒ‡æ ‡
}

// DataCenterInfo æ•°æ®ä¸­å¿ƒä¿¡æ¯
type DataCenterInfo struct {
	ID              DataCenterID
	Region          string
	Zone            string
	NodeList        []NodeID
	IsHealthy       bool
	AverageLatency  time.Duration
	LoadFactor      float64
	LastHealthCheck time.Time
}

// ReadWriteRouter è¯»å†™åˆ†ç¦»è·¯ç”±å™¨
type ReadWriteRouter struct {
	nodeID      NodeID
	config      *ReadWriteRouterConfig
	raftConfig  *Config
	dataCenters map[DataCenterID]*DataCenterInfo
	ctx         context.Context
	cancel      context.CancelFunc
	isRunning   bool
	mu          sync.RWMutex
}

// NewReadWriteRouter åˆ›å»ºæ–°çš„è¯»å†™åˆ†ç¦»è·¯ç”±å™¨
func NewReadWriteRouter(nodeID NodeID, raftConfig *Config) *ReadWriteRouter {
	config := &ReadWriteRouterConfig{
		LoadBalanceAlgorithm: "round-robin",
		HealthCheckInterval:  30 * time.Second,
		MaxLatencyThreshold:  100 * time.Millisecond,
		EnableMetrics:        true,
	}

	ctx, cancel := context.WithCancel(context.Background())

	return &ReadWriteRouter{
		nodeID:      nodeID,
		config:      config,
		raftConfig:  raftConfig,
		dataCenters: make(map[DataCenterID]*DataCenterInfo),
		ctx:         ctx,
		cancel:      cancel,
		isRunning:   false,
	}
}

// Start å¯åŠ¨è¯»å†™åˆ†ç¦»è·¯ç”±å™¨
func (rwr *ReadWriteRouter) Start() error {
	rwr.mu.Lock()
	defer rwr.mu.Unlock()

	if rwr.isRunning {
		return nil
	}

	// åˆå§‹åŒ–æ•°æ®ä¸­å¿ƒä¿¡æ¯
	dcMap := make(map[DataCenterID][]NodeID)
	for _, server := range rwr.raftConfig.Servers {
		dcMap[server.DataCenter] = append(dcMap[server.DataCenter], server.ID)
	}

	for dcID, nodes := range dcMap {
		dcInfo := &DataCenterInfo{
			ID:              dcID,
			NodeList:        nodes,
			IsHealthy:       true,
			AverageLatency:  50 * time.Millisecond,
			LoadFactor:      0.5,
			LastHealthCheck: time.Now(),
		}
		rwr.dataCenters[dcID] = dcInfo
	}

	rwr.isRunning = true
	return nil
}

// Stop åœæ­¢è¯»å†™åˆ†ç¦»è·¯ç”±å™¨
func (rwr *ReadWriteRouter) Stop() error {
	rwr.mu.Lock()
	defer rwr.mu.Unlock()

	if !rwr.isRunning {
		return nil
	}

	rwr.cancel()
	rwr.isRunning = false
	return nil
}

// RouteRequest è·¯ç”±è¯·æ±‚
func (rwr *ReadWriteRouter) RouteRequest(reqType RequestType, key string, consistency ReadConsistencyLevel) (*RoutingDecision, error) {
	rwr.mu.RLock()
	defer rwr.mu.RUnlock()

	if !rwr.isRunning {
		return nil, fmt.Errorf("è¯»å†™åˆ†ç¦»è·¯ç”±å™¨æœªè¿è¡Œ")
	}

	var targetDC DataCenterID
	var targetNode NodeID

	// ç®€å•çš„è·¯ç”±é€»è¾‘
	if reqType == RequestTypeWrite {
		// å†™è¯·æ±‚è·¯ç”±åˆ°æœ¬åœ°DC
		targetDC = rwr.raftConfig.MultiDC.LocalDataCenter.ID
	} else {
		// è¯»è¯·æ±‚æ ¹æ®ä¸€è‡´æ€§çº§åˆ«è·¯ç”±
		switch consistency {
		case ReadConsistencyLinearizable, ReadConsistencyStrong:
			targetDC = rwr.raftConfig.MultiDC.LocalDataCenter.ID
		default:
			// é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„DC
			for dcID := range rwr.dataCenters {
				targetDC = dcID
				break
			}
		}
	}

	// é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹ï¼ˆç®€å•é€‰æ‹©ç¬¬ä¸€ä¸ªï¼‰
	if dcInfo, exists := rwr.dataCenters[targetDC]; exists && len(dcInfo.NodeList) > 0 {
		targetNode = dcInfo.NodeList[0]
	}

	return &RoutingDecision{
		RequestType:       reqType,
		TargetNode:        targetNode,
		TargetDC:          targetDC,
		Latency:           50 * time.Millisecond,
		ConsistencyLevel:  consistency,
		LoadBalanceReason: "simple-selection",
	}, nil
}

// ===== Mockç±»å‹å®šä¹‰ =====

// MockTransport æ¨¡æ‹Ÿä¼ è¾“å±‚
type MockTransport struct {
	nodeID NodeID
	sent   []LogEntry
	mu     sync.RWMutex
}

func (mt *MockTransport) Send(nodeID NodeID, req interface{}) error {
	mt.mu.Lock()
	defer mt.mu.Unlock()
	log.Printf("æ¨¡æ‹Ÿå‘é€åˆ°èŠ‚ç‚¹ %s", nodeID)
	return nil
}

func (mt *MockTransport) Receive() (interface{}, error) {
	return nil, nil
}

// MockStorage æ¨¡æ‹Ÿå­˜å‚¨å±‚
type MockStorage struct {
	logs []LogEntry
	mu   sync.RWMutex
}

func (ms *MockStorage) SaveLogEntries(entries []LogEntry) error {
	ms.mu.Lock()
	defer ms.mu.Unlock()
	ms.logs = append(ms.logs, entries...)
	return nil
}

func (ms *MockStorage) GetLogEntries(startIndex, endIndex LogIndex) ([]LogEntry, error) {
	ms.mu.RLock()
	defer ms.mu.RUnlock()
	if startIndex < 1 || int(endIndex) > len(ms.logs) {
		return nil, fmt.Errorf("ç´¢å¼•è¶…å‡ºèŒƒå›´")
	}
	return ms.logs[startIndex-1 : endIndex], nil
}

func (ms *MockStorage) SaveSnapshot(snapshot Snapshot) error {
	return nil
}

func (ms *MockStorage) GetSnapshot() (Snapshot, error) {
	return Snapshot{}, nil
}

// ===== é›†æˆæµ‹è¯•å¥—ä»¶ =====

// IntegrationTestSuite é›†æˆæµ‹è¯•å¥—ä»¶
type IntegrationTestSuite struct {
	replicator *AsyncReplicator
	router     *ReadWriteRouter
	transport  *MockTransport
	storage    *MockStorage
	config     *Config
}

// NewIntegrationTestSuite åˆ›å»ºé›†æˆæµ‹è¯•å¥—ä»¶
func NewIntegrationTestSuite() *IntegrationTestSuite {
	// åˆ›å»ºå¤šDCæµ‹è¯•é…ç½®
	config := &Config{
		NodeID: "node1",
		MultiDC: &MultiDCConfig{
			Enabled: true,
			LocalDataCenter: DataCenter{
				ID:     "dc1",
				Region: "us-east-1",
			},
		},
		Servers: []ServerConfig{
			// DC1 - ä¸»æ•°æ®ä¸­å¿ƒ
			{ID: "node1", DataCenter: "dc1", Address: "localhost:8001"},
			{ID: "node2", DataCenter: "dc1", Address: "localhost:8002"},
			{ID: "node3", DataCenter: "dc1", Address: "localhost:8003"},

			// DC2 - æ¬¡è¦æ•°æ®ä¸­å¿ƒ
			{ID: "node4", DataCenter: "dc2", Address: "localhost:8004"},
			{ID: "node5", DataCenter: "dc2", Address: "localhost:8005"},

			// DC3 - è¾¹ç¼˜æ•°æ®ä¸­å¿ƒ
			{ID: "node6", DataCenter: "dc3", Address: "localhost:8006"},
		},
	}

	transport := &MockTransport{nodeID: "node1"}
	storage := &MockStorage{logs: make([]LogEntry, 0)}

	// åˆ›å»ºå¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
	replicator := NewAsyncReplicator("node1", config, transport, storage)

	// åˆ›å»ºè¯»å†™åˆ†ç¦»è·¯ç”±å™¨
	router := NewReadWriteRouter("node1", config)

	return &IntegrationTestSuite{
		replicator: replicator,
		router:     router,
		transport:  transport,
		storage:    storage,
		config:     config,
	}
}

// TestBasicIntegration æµ‹è¯•åŸºç¡€é›†æˆåŠŸèƒ½
func (its *IntegrationTestSuite) TestBasicIntegration() error {
	log.Println("=== åŸºç¡€é›†æˆæµ‹è¯• ===")

	// å¯åŠ¨ç»„ä»¶
	if err := its.replicator.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨å¤±è´¥: %v", err)
	}
	defer its.replicator.Stop()

	if err := its.router.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨è¯»å†™åˆ†ç¦»è·¯ç”±å™¨å¤±è´¥: %v", err)
	}
	defer its.router.Stop()

	// ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
	time.Sleep(100 * time.Millisecond)

	log.Println("âœ“ æ‰€æœ‰ç»„ä»¶å¯åŠ¨æˆåŠŸ")

	// æµ‹è¯•å†™è¯·æ±‚è·¯ç”±å’Œå¼‚æ­¥å¤åˆ¶
	writeKey := "user:12345"
	writeDecision, err := its.router.RouteRequest(RequestTypeWrite, writeKey, ReadConsistencyStrong)
	if err != nil {
		return fmt.Errorf("å†™è¯·æ±‚è·¯ç”±å¤±è´¥: %v", err)
	}

	log.Printf("âœ“ å†™è¯·æ±‚è·¯ç”±: é”®=%s, ç›®æ ‡èŠ‚ç‚¹=%s, ç›®æ ‡DC=%s",
		writeKey, writeDecision.TargetNode, writeDecision.TargetDC)

	// æ¨¡æ‹Ÿå†™æ“ä½œäº§ç”Ÿçš„æ—¥å¿—æ¡ç›®
	logEntries := []LogEntry{
		{Index: 1, Term: 1, Data: []byte(fmt.Sprintf("SET %s value1", writeKey))},
		{Index: 2, Term: 1, Data: []byte(fmt.Sprintf("SET %s value2", writeKey))},
	}

	// æ‰§è¡Œå¼‚æ­¥å¤åˆ¶
	err = its.replicator.ReplicateAsync(logEntries)
	if err != nil {
		return fmt.Errorf("å¼‚æ­¥å¤åˆ¶å¤±è´¥: %v", err)
	}

	log.Printf("âœ“ å¼‚æ­¥å¤åˆ¶å¯åŠ¨: %dæ¡æ—¥å¿—æ¡ç›®", len(logEntries))

	// æµ‹è¯•è¯»è¯·æ±‚è·¯ç”±
	readKey := "user:12345"
	readDecision, err := its.router.RouteRequest(RequestTypeRead, readKey, ReadConsistencyEventual)
	if err != nil {
		return fmt.Errorf("è¯»è¯·æ±‚è·¯ç”±å¤±è´¥: %v", err)
	}

	log.Printf("âœ“ è¯»è¯·æ±‚è·¯ç”±: é”®=%s, ç›®æ ‡èŠ‚ç‚¹=%s, ç›®æ ‡DC=%s",
		readKey, readDecision.TargetNode, readDecision.TargetDC)

	// ç­‰å¾…å¼‚æ­¥å¤åˆ¶å®Œæˆ
	time.Sleep(200 * time.Millisecond)

	return nil
}

// TestConsistencyLevels æµ‹è¯•ä¸åŒä¸€è‡´æ€§çº§åˆ«
func (its *IntegrationTestSuite) TestConsistencyLevels() error {
	log.Println("\n=== ä¸€è‡´æ€§çº§åˆ«æµ‹è¯• ===")

	// å¯åŠ¨ç»„ä»¶
	if err := its.replicator.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨å¤±è´¥: %v", err)
	}
	defer its.replicator.Stop()

	if err := its.router.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨è¯»å†™åˆ†ç¦»è·¯ç”±å™¨å¤±è´¥: %v", err)
	}
	defer its.router.Stop()

	// ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
	time.Sleep(100 * time.Millisecond)

	// æµ‹è¯•ä¸åŒä¸€è‡´æ€§çº§åˆ«çš„è·¯ç”±
	testCases := []struct {
		key         string
		consistency ReadConsistencyLevel
		description string
	}{
		{"data:eventual", ReadConsistencyEventual, "æœ€ç»ˆä¸€è‡´æ€§"},
		{"data:bounded", ReadConsistencyBounded, "æœ‰ç•Œä¸€è‡´æ€§"},
		{"data:strong", ReadConsistencyStrong, "å¼ºä¸€è‡´æ€§"},
		{"data:linearizable", ReadConsistencyLinearizable, "çº¿æ€§ä¸€è‡´æ€§"},
	}

	for _, tc := range testCases {
		decision, err := its.router.RouteRequest(RequestTypeRead, tc.key, tc.consistency)
		if err != nil {
			return fmt.Errorf("%sè·¯ç”±å¤±è´¥: %v", tc.description, err)
		}

		log.Printf("âœ“ %s: é”®=%s, ç›®æ ‡èŠ‚ç‚¹=%s, ç›®æ ‡DC=%s",
			tc.description, tc.key, decision.TargetNode, decision.TargetDC)
	}

	return nil
}

// TestLoadBalancingIntegration æµ‹è¯•è´Ÿè½½å‡è¡¡é›†æˆ
func (its *IntegrationTestSuite) TestLoadBalancingIntegration() error {
	log.Println("\n=== è´Ÿè½½å‡è¡¡é›†æˆæµ‹è¯• ===")

	// å¯åŠ¨ç»„ä»¶
	if err := its.router.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨è¯»å†™åˆ†ç¦»è·¯ç”±å™¨å¤±è´¥: %v", err)
	}
	defer its.router.Stop()

	// ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
	time.Sleep(100 * time.Millisecond)

	// æ‰§è¡Œå¤šæ¬¡è·¯ç”±è¯·æ±‚ï¼ŒéªŒè¯è´Ÿè½½å‡è¡¡
	nodeCount := make(map[NodeID]int)
	dcCount := make(map[DataCenterID]int)

	requestCount := 20
	for i := 0; i < requestCount; i++ {
		key := fmt.Sprintf("load-test-key-%d", i)
		decision, err := its.router.RouteRequest(RequestTypeRead, key, ReadConsistencyEventual)
		if err != nil {
			return fmt.Errorf("è´Ÿè½½å‡è¡¡æµ‹è¯•è·¯ç”±å¤±è´¥ (è¯·æ±‚%d): %v", i, err)
		}

		nodeCount[decision.TargetNode]++
		dcCount[decision.TargetDC]++
	}

	log.Println("âœ“ è´Ÿè½½å‡è¡¡ç»Ÿè®¡:")
	log.Println("  èŠ‚ç‚¹åˆ†å¸ƒ:")
	for nodeID, count := range nodeCount {
		percentage := float64(count) / float64(requestCount) * 100
		log.Printf("    èŠ‚ç‚¹ %s: %d æ¬¡ (%.1f%%)", nodeID, count, percentage)
	}

	log.Println("  DCåˆ†å¸ƒ:")
	for dcID, count := range dcCount {
		percentage := float64(count) / float64(requestCount) * 100
		log.Printf("    DC %s: %d æ¬¡ (%.1f%%)", dcID, count, percentage)
	}

	return nil
}

// TestFailoverScenario æµ‹è¯•æ•…éšœè½¬ç§»åœºæ™¯
func (its *IntegrationTestSuite) TestFailoverScenario() error {
	log.Println("\n=== æ•…éšœè½¬ç§»åœºæ™¯æµ‹è¯• ===")

	// å¯åŠ¨ç»„ä»¶
	if err := its.replicator.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨å¤±è´¥: %v", err)
	}
	defer its.replicator.Stop()

	if err := its.router.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨è¯»å†™åˆ†ç¦»è·¯ç”±å™¨å¤±è´¥: %v", err)
	}
	defer its.router.Stop()

	// ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
	time.Sleep(100 * time.Millisecond)

	// æ¨¡æ‹Ÿæ­£å¸¸æ“ä½œ
	normalKey := "failover:test"
	decision, err := its.router.RouteRequest(RequestTypeWrite, normalKey, ReadConsistencyStrong)
	if err != nil {
		return fmt.Errorf("æ­£å¸¸å†™è¯·æ±‚è·¯ç”±å¤±è´¥: %v", err)
	}

	log.Printf("âœ“ æ­£å¸¸å†™è¯·æ±‚: é”®=%s, ç›®æ ‡èŠ‚ç‚¹=%s, ç›®æ ‡DC=%s",
		normalKey, decision.TargetNode, decision.TargetDC)

	// æ¨¡æ‹Ÿå¼‚æ­¥å¤åˆ¶
	entries := []LogEntry{
		{Index: 1, Term: 1, Data: []byte("failover test data")},
	}

	err = its.replicator.ReplicateAsync(entries)
	if err != nil {
		return fmt.Errorf("æ•…éšœè½¬ç§»åœºæ™¯å¼‚æ­¥å¤åˆ¶å¤±è´¥: %v", err)
	}

	log.Println("âœ“ æ•…éšœè½¬ç§»åœºæ™¯æ¨¡æ‹Ÿå®Œæˆ")

	return nil
}

// TestMetricsIntegration æµ‹è¯•æŒ‡æ ‡é›†æˆ
func (its *IntegrationTestSuite) TestMetricsIntegration() error {
	log.Println("\n=== æŒ‡æ ‡é›†æˆæµ‹è¯• ===")

	// å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
	if err := its.replicator.Start(); err != nil {
		return fmt.Errorf("å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨å¤±è´¥: %v", err)
	}
	defer its.replicator.Stop()

	// åˆ›å»ºæµ‹è¯•æ—¥å¿—æ¡ç›®
	entries := []LogEntry{
		{Index: 1, Term: 1, Data: []byte("metrics-test-1")},
		{Index: 2, Term: 1, Data: []byte("metrics-test-2")},
		{Index: 3, Term: 1, Data: []byte("metrics-test-3")},
	}

	// æ‰§è¡Œå¼‚æ­¥å¤åˆ¶
	err := its.replicator.ReplicateAsync(entries)
	if err != nil {
		return fmt.Errorf("æŒ‡æ ‡æµ‹è¯•å¼‚æ­¥å¤åˆ¶å¤±è´¥: %v", err)
	}

	// ç­‰å¾…å¤„ç†
	time.Sleep(200 * time.Millisecond)

	// æ£€æŸ¥å¤åˆ¶çŠ¶æ€
	status := its.replicator.GetReplicationStatus()
	log.Printf("âœ“ å¤åˆ¶ç›®æ ‡æ•°é‡: %d", len(status))

	for dcID, target := range status {
		log.Printf("âœ“ DC %s: å¥åº·=%t, æœ€åæ£€æŸ¥=%v",
			dcID, target.IsHealthy, target.HealthCheckTime.Format("15:04:05"))
	}

	// æ£€æŸ¥æŒ‡æ ‡
	metrics := its.replicator.GetMetrics()
	log.Printf("âœ“ å¤åˆ¶æŒ‡æ ‡: æ‰¹æ¬¡=%d, æ¡ç›®=%d, å­—èŠ‚=%d",
		metrics.TotalBatchesSent,
		metrics.TotalEntriesReplicated,
		metrics.TotalBytesTransferred)

	if metrics.TotalBatchesSent == 0 {
		return fmt.Errorf("æ‰¹æ¬¡è®¡æ•°åº”è¯¥å¤§äº0")
	}

	return nil
}

// RunAllTests è¿è¡Œæ‰€æœ‰æµ‹è¯•
func (its *IntegrationTestSuite) RunAllTests() error {
	log.Println("ğŸš€ å¼€å§‹è¿è¡Œå¼‚æ­¥å¤åˆ¶é›†æˆæµ‹è¯•å¥—ä»¶...")

	tests := []struct {
		name string
		test func() error
	}{
		{"åŸºç¡€é›†æˆæµ‹è¯•", its.TestBasicIntegration},
		{"ä¸€è‡´æ€§çº§åˆ«æµ‹è¯•", its.TestConsistencyLevels},
		{"è´Ÿè½½å‡è¡¡é›†æˆæµ‹è¯•", its.TestLoadBalancingIntegration},
		{"æ•…éšœè½¬ç§»åœºæ™¯æµ‹è¯•", its.TestFailoverScenario},
		{"æŒ‡æ ‡é›†æˆæµ‹è¯•", its.TestMetricsIntegration},
	}

	for i, test := range tests {
		log.Printf("\n--- æµ‹è¯• %d/%d: %s ---", i+1, len(tests), test.name)

		if err := test.test(); err != nil {
			return fmt.Errorf("%så¤±è´¥: %v", test.name, err)
		}

		log.Printf("âœ… %så®Œæˆ", test.name)

		// æµ‹è¯•é—´ä¼‘æ¯
		time.Sleep(100 * time.Millisecond)
	}

	return nil
}

func main() {
	log.Println("ğŸ¯ ConcordKV Phase 5.2.2 å¼‚æ­¥å¤åˆ¶é›†æˆæµ‹è¯•")
	log.Println("=" + fmt.Sprintf("%50s", "") + "=")

	// åˆ›å»ºæµ‹è¯•å¥—ä»¶
	suite := NewIntegrationTestSuite()

	// è¿è¡Œæ‰€æœ‰æµ‹è¯•
	if err := suite.RunAllTests(); err != nil {
		log.Fatalf("âŒ é›†æˆæµ‹è¯•å¤±è´¥: %v", err)
	}

	log.Println("\nğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡! Phase 5.2.2 å¼‚æ­¥å¤åˆ¶åŠŸèƒ½éªŒè¯æˆåŠŸ!")
	log.Println("âœ… åŸºç¡€é›†æˆåŠŸèƒ½å®Œæ•´")
	log.Println("âœ… ä¸€è‡´æ€§çº§åˆ«æ”¯æŒå®Œæ•´")
	log.Println("âœ… è´Ÿè½½å‡è¡¡æœºåˆ¶éªŒè¯")
	log.Println("âœ… æ•…éšœè½¬ç§»åœºæ™¯æµ‹è¯•é€šè¿‡")
	log.Println("âœ… æŒ‡æ ‡é›†æˆåŠŸèƒ½éªŒè¯")
}
