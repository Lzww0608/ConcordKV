/*
 * @Author: Lzww0608
 * @Date: 2025-1-28 23:25:00
 * @LastEditors: Lzww0608
 * @LastEditTime: 2025-1-28 23:25:00
 * @Description: ConcordKV å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨ç®€åŒ–æµ‹è¯•
 */

package main

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"
)

// ===== åŸºç¡€ç±»å‹å®šä¹‰ =====

// NodeID èŠ‚ç‚¹IDç±»å‹
type NodeID string

// DataCenterID æ•°æ®ä¸­å¿ƒIDç±»å‹
type DataCenterID string

// LogIndex æ—¥å¿—ç´¢å¼•ç±»å‹
type LogIndex uint64

// Term Raftä»»æœŸç±»å‹
type Term uint64

// LogEntry Raftæ—¥å¿—æ¡ç›®
type LogEntry struct {
	Index LogIndex
	Term  Term
	Data  []byte
}

// Snapshot Raftå¿«ç…§
type Snapshot struct {
	Index LogIndex
	Term  Term
	Data  []byte
}

// DataCenter æ•°æ®ä¸­å¿ƒé…ç½®
type DataCenter struct {
	ID     DataCenterID
	Region string
}

// ServerConfig æœåŠ¡å™¨é…ç½®
type ServerConfig struct {
	ID         NodeID
	DataCenter DataCenterID
	Address    string
}

// MultiDCConfig å¤šæ•°æ®ä¸­å¿ƒé…ç½®
type MultiDCConfig struct {
	Enabled         bool
	LocalDataCenter DataCenter
}

// Config Rafté…ç½®
type Config struct {
	NodeID  NodeID
	MultiDC *MultiDCConfig
	Servers []ServerConfig
}

// Transport ä¼ è¾“å±‚æ¥å£
type Transport interface {
	Send(nodeID NodeID, req interface{}) error
	Receive() (interface{}, error)
}

// Storage å­˜å‚¨å±‚æ¥å£
type Storage interface {
	SaveLogEntries(entries []LogEntry) error
	GetLogEntries(startIndex, endIndex LogIndex) ([]LogEntry, error)
	SaveSnapshot(snapshot Snapshot) error
	GetSnapshot() (Snapshot, error)
}

// ===== å¼‚æ­¥å¤åˆ¶ç›¸å…³ç±»å‹ =====

// AsyncReplicationConfig å¼‚æ­¥å¤åˆ¶é…ç½®
type AsyncReplicationConfig struct {
	BatchSize          int           // æ‰¹æ¬¡å¤§å°
	FlushInterval      time.Duration // åˆ·æ–°é—´éš”
	RetryDelay         time.Duration // é‡è¯•å»¶è¿Ÿ
	MaxRetries         int           // æœ€å¤§é‡è¯•æ¬¡æ•°
	CompressionEnabled bool          // æ˜¯å¦å¯ç”¨å‹ç¼©
	MonitoringEnabled  bool          // æ˜¯å¦å¯ç”¨ç›‘æ§
}

// AsyncReplicationTarget å¼‚æ­¥å¤åˆ¶ç›®æ ‡
type AsyncReplicationTarget struct {
	DataCenterID        DataCenterID
	NodeList            []NodeID
	LastReplicatedIndex LogIndex
	LastReplicatedTerm  Term
	LastReplicationTime time.Time
	PendingBatches      int
	ReplicationLatency  time.Duration
	IsHealthy           bool
	HealthCheckTime     time.Time
	NetworkLatency      time.Duration
	ThroughputMBps      float64
}

// AsyncReplicationMetrics å¼‚æ­¥å¤åˆ¶æŒ‡æ ‡
type AsyncReplicationMetrics struct {
	TotalBatchesSent       uint64
	TotalEntriesReplicated uint64
	TotalBytesTransferred  uint64
	AverageLatency         time.Duration
	MaxLatency             time.Duration
	MinLatency             time.Duration
	SuccessRate            float64
	ErrorCount             uint64
	RetryCount             uint64
	LastErrorTime          time.Time
	DataCenterMetrics      map[DataCenterID]*DataCenterMetrics
}

// DataCenterMetrics æ•°æ®ä¸­å¿ƒæŒ‡æ ‡
type DataCenterMetrics struct {
	BatchesSent       uint64
	EntriesReplicated uint64
	BytesTransferred  uint64
	AverageLatency    time.Duration
	SuccessRate       float64
	ErrorCount        uint64
}

// AsyncReplicator å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
type AsyncReplicator struct {
	nodeID     NodeID
	config     *AsyncReplicationConfig
	raftConfig *Config
	transport  Transport
	storage    Storage
	targets    map[DataCenterID]*AsyncReplicationTarget
	metrics    *AsyncReplicationMetrics
	ctx        context.Context
	cancel     context.CancelFunc
	isRunning  bool
	mu         sync.RWMutex
}

// NewAsyncReplicator åˆ›å»ºæ–°çš„å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
func NewAsyncReplicator(nodeID NodeID, raftConfig *Config, transport Transport, storage Storage) *AsyncReplicator {
	config := &AsyncReplicationConfig{
		BatchSize:          100,
		FlushInterval:      1 * time.Second,
		RetryDelay:         500 * time.Millisecond,
		MaxRetries:         3,
		CompressionEnabled: true,
		MonitoringEnabled:  true,
	}

	ctx, cancel := context.WithCancel(context.Background())

	return &AsyncReplicator{
		nodeID:     nodeID,
		config:     config,
		raftConfig: raftConfig,
		transport:  transport,
		storage:    storage,
		targets:    make(map[DataCenterID]*AsyncReplicationTarget),
		metrics: &AsyncReplicationMetrics{
			DataCenterMetrics: make(map[DataCenterID]*DataCenterMetrics),
		},
		ctx:       ctx,
		cancel:    cancel,
		isRunning: false,
	}
}

// Start å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
func (ar *AsyncReplicator) Start() error {
	ar.mu.Lock()
	defer ar.mu.Unlock()

	if ar.isRunning {
		return nil
	}

	// åˆå§‹åŒ–å¤åˆ¶ç›®æ ‡
	for _, server := range ar.raftConfig.Servers {
		if server.DataCenter != ar.raftConfig.MultiDC.LocalDataCenter.ID {
			target := &AsyncReplicationTarget{
				DataCenterID:    server.DataCenter,
				NodeList:        []NodeID{server.ID},
				IsHealthy:       true,
				HealthCheckTime: time.Now(),
			}
			ar.targets[server.DataCenter] = target
			ar.metrics.DataCenterMetrics[server.DataCenter] = &DataCenterMetrics{}
		}
	}

	ar.isRunning = true
	return nil
}

// Stop åœæ­¢å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
func (ar *AsyncReplicator) Stop() error {
	ar.mu.Lock()
	defer ar.mu.Unlock()

	if !ar.isRunning {
		return nil
	}

	ar.cancel()
	ar.isRunning = false
	return nil
}

// ReplicateAsync æ‰§è¡Œå¼‚æ­¥å¤åˆ¶
func (ar *AsyncReplicator) ReplicateAsync(entries []LogEntry) error {
	ar.mu.RLock()
	defer ar.mu.RUnlock()

	if !ar.isRunning {
		return fmt.Errorf("å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨æœªè¿è¡Œ")
	}

	// æ›´æ–°æŒ‡æ ‡
	ar.metrics.TotalEntriesReplicated += uint64(len(entries))
	ar.metrics.TotalBatchesSent++

	return nil
}

// GetReplicationStatus è·å–å¤åˆ¶çŠ¶æ€
func (ar *AsyncReplicator) GetReplicationStatus() map[DataCenterID]*AsyncReplicationTarget {
	ar.mu.RLock()
	defer ar.mu.RUnlock()

	status := make(map[DataCenterID]*AsyncReplicationTarget)
	for dcID, target := range ar.targets {
		// å¤åˆ¶ä¸€ä»½çŠ¶æ€é¿å…å¹¶å‘é—®é¢˜
		statusCopy := *target
		status[dcID] = &statusCopy
	}
	return status
}

// GetMetrics è·å–å¤åˆ¶æŒ‡æ ‡
func (ar *AsyncReplicator) GetMetrics() *AsyncReplicationMetrics {
	ar.mu.RLock()
	defer ar.mu.RUnlock()

	// è¿”å›æŒ‡æ ‡çš„å‰¯æœ¬
	metricsCopy := *ar.metrics
	return &metricsCopy
}

// ===== Mockç±»å‹å®šä¹‰ =====

// MockTransport æ¨¡æ‹Ÿä¼ è¾“å±‚
type MockTransport struct {
	NodeID NodeID
	Sent   []LogEntry
	mu     sync.RWMutex
}

func (mt *MockTransport) Send(nodeID NodeID, req interface{}) error {
	mt.mu.Lock()
	defer mt.mu.Unlock()
	log.Printf("æ¨¡æ‹Ÿå‘é€åˆ°èŠ‚ç‚¹ %s", nodeID)
	return nil
}

func (mt *MockTransport) Receive() (interface{}, error) {
	return nil, nil
}

// MockStorage æ¨¡æ‹Ÿå­˜å‚¨å±‚
type MockStorage struct {
	Logs []LogEntry
	mu   sync.RWMutex
}

func (ms *MockStorage) SaveLogEntries(entries []LogEntry) error {
	ms.mu.Lock()
	defer ms.mu.Unlock()
	ms.Logs = append(ms.Logs, entries...)
	return nil
}

func (ms *MockStorage) GetLogEntries(startIndex, endIndex LogIndex) ([]LogEntry, error) {
	ms.mu.RLock()
	defer ms.mu.RUnlock()
	if startIndex < 1 || int(endIndex) > len(ms.Logs) {
		return nil, fmt.Errorf("ç´¢å¼•è¶…å‡ºèŒƒå›´")
	}
	return ms.Logs[startIndex-1 : endIndex], nil
}

func (ms *MockStorage) SaveSnapshot(snapshot Snapshot) error {
	return nil
}

func (ms *MockStorage) GetSnapshot() (Snapshot, error) {
	return Snapshot{}, nil
}

// ===== æµ‹è¯•å‡½æ•° =====

// createTestAsyncReplicator åˆ›å»ºæµ‹è¯•ç”¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨
func createTestAsyncReplicator() *AsyncReplicator {
	// åˆ›å»ºæµ‹è¯•é…ç½®
	raftConfig := &Config{
		NodeID: "node1",
		MultiDC: &MultiDCConfig{
			Enabled: true,
			LocalDataCenter: DataCenter{
				ID:     "dc1",
				Region: "us-east-1",
			},
		},
		Servers: []ServerConfig{
			{ID: "node1", DataCenter: "dc1", Address: "localhost:8001"},
			{ID: "node2", DataCenter: "dc1", Address: "localhost:8002"},
			{ID: "node3", DataCenter: "dc2", Address: "localhost:8003"},
			{ID: "node4", DataCenter: "dc2", Address: "localhost:8004"},
		},
	}

	transport := &MockTransport{NodeID: "node1"}
	storage := &MockStorage{Logs: make([]LogEntry, 0)}

	return NewAsyncReplicator("node1", raftConfig, transport, storage)
}

// testAsyncReplicatorCreation æµ‹è¯•å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨åˆ›å»º
func testAsyncReplicatorCreation() error {
	replicator := createTestAsyncReplicator()

	if replicator == nil {
		return fmt.Errorf("å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨åˆ›å»ºå¤±è´¥")
	}

	log.Println("âœ“ å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
	return nil
}

// testAsyncReplication æµ‹è¯•å¼‚æ­¥å¤åˆ¶åŠŸèƒ½
func testAsyncReplication() error {
	replicator := createTestAsyncReplicator()

	// å¯åŠ¨å¤åˆ¶ç®¡ç†å™¨
	err := replicator.Start()
	if err != nil {
		return fmt.Errorf("å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨å¤±è´¥: %v", err)
	}
	defer replicator.Stop()

	// åˆ›å»ºæµ‹è¯•æ—¥å¿—æ¡ç›®
	entries := []LogEntry{
		{Index: 1, Term: 1, Data: []byte("test-data-1")},
		{Index: 2, Term: 1, Data: []byte("test-data-2")},
		{Index: 3, Term: 1, Data: []byte("test-data-3")},
	}

	// æ‰§è¡Œå¼‚æ­¥å¤åˆ¶
	err = replicator.ReplicateAsync(entries)
	if err != nil {
		return fmt.Errorf("å¼‚æ­¥å¤åˆ¶å¤±è´¥: %v", err)
	}

	log.Println("âœ“ å¼‚æ­¥å¤åˆ¶è¯·æ±‚å‘é€æˆåŠŸ")

	// ç­‰å¾…å¤åˆ¶å¤„ç†
	time.Sleep(100 * time.Millisecond)

	// æ£€æŸ¥å¤åˆ¶çŠ¶æ€
	status := replicator.GetReplicationStatus()
	if len(status) == 0 {
		return fmt.Errorf("æœªæ‰¾åˆ°å¤åˆ¶ç›®æ ‡")
	}

	for dcID, target := range status {
		log.Printf("âœ“ DC %s å¤åˆ¶çŠ¶æ€: æœ€åå¤åˆ¶ç´¢å¼•=%d, å¥åº·çŠ¶æ€=%t",
			dcID, target.LastReplicatedIndex, target.IsHealthy)
	}

	// æ£€æŸ¥æŒ‡æ ‡
	metrics := replicator.GetMetrics()
	if metrics.TotalBatchesSent == 0 {
		return fmt.Errorf("æ‰¹æ¬¡è®¡æ•°åº”è¯¥å¤§äº0")
	}
	if metrics.TotalEntriesReplicated == 0 {
		return fmt.Errorf("æ¡ç›®è®¡æ•°åº”è¯¥å¤§äº0")
	}

	log.Printf("âœ“ å¤åˆ¶æŒ‡æ ‡: æ‰¹æ¬¡=%d, æ¡ç›®=%d, å­—èŠ‚=%d",
		metrics.TotalBatchesSent,
		metrics.TotalEntriesReplicated,
		metrics.TotalBytesTransferred)

	return nil
}

// testReplicationMetrics æµ‹è¯•å¤åˆ¶æŒ‡æ ‡åŠŸèƒ½
func testReplicationMetrics() error {
	replicator := createTestAsyncReplicator()

	// å¯åŠ¨å¤åˆ¶ç®¡ç†å™¨
	err := replicator.Start()
	if err != nil {
		return fmt.Errorf("å¯åŠ¨å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨å¤±è´¥: %v", err)
	}
	defer replicator.Stop()

	// å¤šæ‰¹æ¬¡å¤åˆ¶æµ‹è¯•
	for i := 0; i < 5; i++ {
		entries := []LogEntry{
			{Index: LogIndex(i*2 + 1), Term: 1, Data: []byte(fmt.Sprintf("batch-%d-data-1", i))},
			{Index: LogIndex(i*2 + 2), Term: 1, Data: []byte(fmt.Sprintf("batch-%d-data-2", i))},
		}

		err = replicator.ReplicateAsync(entries)
		if err != nil {
			return fmt.Errorf("æ‰¹æ¬¡ %d å¼‚æ­¥å¤åˆ¶å¤±è´¥: %v", i, err)
		}

		time.Sleep(50 * time.Millisecond)
	}

	// æ£€æŸ¥æœ€ç»ˆæŒ‡æ ‡
	metrics := replicator.GetMetrics()
	log.Printf("âœ“ æœ€ç»ˆå¤åˆ¶æŒ‡æ ‡: æ‰¹æ¬¡=%d, æ¡ç›®=%d",
		metrics.TotalBatchesSent,
		metrics.TotalEntriesReplicated)

	if metrics.TotalBatchesSent != 5 {
		return fmt.Errorf("æœŸæœ›æ‰¹æ¬¡æ•°=5, å®é™…=%d", metrics.TotalBatchesSent)
	}

	if metrics.TotalEntriesReplicated != 10 {
		return fmt.Errorf("æœŸæœ›æ¡ç›®æ•°=10, å®é™…=%d", metrics.TotalEntriesReplicated)
	}

	return nil
}

// runAsyncReplicatorTest è¿è¡Œå¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨æµ‹è¯•çš„ä¸»å‡½æ•°
func runAsyncReplicatorTest() error {
	log.Println("=== å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨åŠŸèƒ½æµ‹è¯• ===")

	tests := []struct {
		name string
		test func() error
	}{
		{"å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨åˆ›å»ºæµ‹è¯•", testAsyncReplicatorCreation},
		{"å¼‚æ­¥å¤åˆ¶åŠŸèƒ½æµ‹è¯•", testAsyncReplication},
		{"å¤åˆ¶æŒ‡æ ‡æµ‹è¯•", testReplicationMetrics},
	}

	for i, test := range tests {
		log.Printf("--- æµ‹è¯• %d/%d: %s ---", i+1, len(tests), test.name)

		if err := test.test(); err != nil {
			return fmt.Errorf("%så¤±è´¥: %v", test.name, err)
		}

		log.Printf("âœ… %så®Œæˆ", test.name)

		// æµ‹è¯•é—´ä¼‘æ¯
		time.Sleep(50 * time.Millisecond)
	}

	return nil
}

func main() {
	log.Println("ğŸ¯ ConcordKV å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨ç®€åŒ–æµ‹è¯•")
	log.Println("=" + fmt.Sprintf("%45s", "") + "=")

	// è¿è¡Œæµ‹è¯•
	if err := runAsyncReplicatorTest(); err != nil {
		log.Fatalf("âŒ æµ‹è¯•å¤±è´¥: %v", err)
	}

	log.Println("\nğŸ‰ å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨æµ‹è¯•å®Œæˆ!")
	log.Println("âœ… å¼‚æ­¥å¤åˆ¶ç®¡ç†å™¨åˆ›å»ºåŠŸèƒ½éªŒè¯")
	log.Println("âœ… å¼‚æ­¥å¤åˆ¶æ ¸å¿ƒåŠŸèƒ½éªŒè¯")
	log.Println("âœ… å¤åˆ¶æŒ‡æ ‡ç»Ÿè®¡åŠŸèƒ½éªŒè¯")
}
